name: Update README

on:
  schedule:
    - cron: '*/5 * * * *'  # Runs every 5 minutes
  workflow_dispatch:

jobs:
  archive:
    runs-on: ubuntu-latest
    steps:
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests

    - name: Extract and archive video URLs
      env:
        RUN_NUMBER: ${{ github.run_number }}
      run: |
        python <<EOF
        import requests

        def check_archive_status(url):
            api_url = f"http://archive.org/wayback/available?url={url}"
            response = requests.get(api_url)
            data = response.json()
            return data['archived_snapshots'] != {}

        def archive_url(url):
            if check_archive_status(url):
                print(f"Already archived: {url}")
                return

            archive_url = f"https://web.archive.org/save/{url}"
            response = requests.get(archive_url)
            print(f"Newly archived: {url}")
            print(f"Archive URL: {archive_url}")

        def find_video_sources(html):
            sources = []
            start = 0
            while True:
                video_start = html.find('<video', start)
                if video_start == -1:
                    break
                video_end = html.find('</video>', video_start)
                if video_end == -1:
                    break
                video_tag = html[video_start:video_end]
                
                source_start = 0
                while True:
                    source_start = video_tag.find('<source', source_start)
                    if source_start == -1:
                        break
                    src_start = video_tag.find('src="', source_start)
                    if src_start == -1:
                        break
                    src_start += 5  # Length of 'src="'
                    src_end = video_tag.find('"', src_start)
                    if src_end == -1:
                        break
                    src = video_tag[src_start:src_end]
                    sources.append(src)
                    source_start = src_end
                
                start = video_end

            return sources

        run_number = int("$RUN_NUMBER")
        url = f"https://www.britishpathe.com/asset/{run_number + 52000}"
        
        response = requests.get(url)
        html_content = response.text
        
        video_sources = find_video_sources(html_content)
        
        for src in video_sources:
            print(f"Found video source: {src}")
            archive_url(src)
        
        # Archive the main page as well
        archive_url(url)
        EOF
